{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BART model and tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "        category_name                                       reviews.text\n",
      "0           Fire HD 8  this product so far has not disappointed. my c...\n",
      "1           Fire KIDS  the tablet is very light and streams well. i o...\n",
      "2       Fire Tablet 7  good basic tablet for checking email , web bro...\n",
      "3              Kindle  very lightweight and portable with excellent b...\n",
      "4  Speakers/Streaming  i really enjoy the echo. i got an echo dot and...\n"
     ]
    }
   ],
   "source": [
    "# LOAD the DATA (the output DS from K-means clustering)\n",
    "file_path = 'categorized_dataset_k5_with_names.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Data cleaning: Convert reviews.text to lowercase and remove nulls\n",
    "df['reviews.text'] = df['reviews.text'].astype(str).str.lower()\n",
    "df = df[df['reviews.text'].notnull()]\n",
    "\n",
    "# Group all reviews under each category_name\n",
    "grouped_reviews = df.groupby('category_name')['reviews.text'].apply(lambda texts: ' '.join(texts)).reset_index()\n",
    "\n",
    "print(grouped_reviews.shape)\n",
    "print(grouped_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        category_name                                       reviews.text  \\\n",
      "0           Fire HD 8  this product so far has not disappointed. my c...   \n",
      "1           Fire KIDS  the tablet is very light and streams well. i o...   \n",
      "2       Fire Tablet 7  good basic tablet for checking email , web bro...   \n",
      "3              Kindle  very lightweight and portable with excellent b...   \n",
      "4  Speakers/Streaming  i really enjoy the echo. i got an echo dot and...   \n",
      "\n",
      "                                        blog_summary  \\\n",
      "0  i love being able to easily access all of the ...   \n",
      "1  i only use it to stream movies and it's much l...   \n",
      "2  i love this tablet as much as my firsdt one! e...   \n",
      "3  The Kindle Oasis is very lightweight and porta...   \n",
      "4   echo dot is great at voice recognition - you ...   \n",
      "\n",
      "                                          highlights  \\\n",
      "0  i love being able to easily access all of the ...   \n",
      "1  i only use it to stream movies and it's much l...   \n",
      "2  i love this tablet as much as my firsdt one! e...   \n",
      "3  The Kindle Oasis is very lightweight and porta...   \n",
      "4   echo dot has the same capability as the full ...   \n",
      "\n",
      "                                              issues  \n",
      "0  i love being able to easily access all of the ...  \n",
      "1  i only use it to stream movies and it's much l...  \n",
      "2  i love this tablet as much as my firsdt one! e...  \n",
      "3  The Kindle Oasis is very lightweight and porta...  \n",
      "4   echo dot is great at voice recognition - you ...  \n"
     ]
    }
   ],
   "source": [
    "# VERSION 2 to make Summary, Highlight and Issues mutually exclusive.\n",
    "\n",
    "# Function to generate summary, highlights, and issues with distinct instructions\n",
    "def generate_summary_highlights_issues(text, category_name):\n",
    "    # Generate blog-style summary\n",
    "    summary_prompt = f\"Generate a summary for a blog that covers the specifications, features, and configurations of a product in the category: {category_name}. Here are the reviews: \" + text\n",
    "    summary_ids = model.generate(tokenizer.encode(summary_prompt, return_tensors=\"pt\", max_length=1024, truncation=True), max_length=500, num_beams=2, length_penalty=2.0, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Generate highlights focusing on positive aspects not in the summary\n",
    "    # highlight_prompt = f\"Generate 3-4 positive points that are not covered in the summary: {summary}. Here are the reviews: \" + text\n",
    "    highlight_prompt = f\"Generate 3-4 bullet points of positive features and advantages over competitors that are not mentioned in the summary: {summary}. Focus on product strengths and customer satisfaction for the product in the category: {category_name}. Here are the reviews: \" + text\n",
    "    highlights_ids = model.generate(tokenizer.encode(highlight_prompt, return_tensors=\"pt\", max_length=1024, truncation=True), max_length=150, num_beams=2, length_penalty=1.5, early_stopping=True)\n",
    "    highlights = tokenizer.decode(highlights_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Generate issues focusing on negative aspects not in the summary or highlights\n",
    "    # issue_prompt = f\"Generate 3-4 negative points that are not covered in the summary: {summary} or highlights: {highlights}. Here are the reviews: \" + text\n",
    "    issue_prompt = f\"Generate 2-3 bullet points of negative features or issues with the product that are not mentioned in the summary: {summary} or highlights: {highlights}. Focus on customer complaints, problems, or disadvantages compared to competitors for the product in the category: {category_name}. Here are the reviews: \" + text\n",
    "    issues_ids = model.generate(tokenizer.encode(issue_prompt, return_tensors=\"pt\", max_length=1024, truncation=True), max_length=100, num_beams=2, length_penalty=1.5, early_stopping=True)\n",
    "    issues = tokenizer.decode(issues_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary, highlights, issues\n",
    "\n",
    "# Apply the function to each category\n",
    "\n",
    "grouped_reviews['blog_summary'], grouped_reviews['highlights'], grouped_reviews['issues'] = zip(*grouped_reviews.apply(\n",
    "    lambda row: generate_summary_highlights_issues(row['reviews.text'], row['category_name']), axis=1))\n",
    "\n",
    "print(grouped_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output to an HTML file\n",
    "with open('BART_summaries_prefinal.html', 'w') as f:\n",
    "    f.write('<html><body>')\n",
    "    \n",
    "    for index, row in grouped_reviews.iterrows():\n",
    "        f.write(f\"<h2>Product: {row['category_name']}</h2>\")\n",
    "        \n",
    "        f.write(\"<h3>Summary</h3>\")\n",
    "        f.write(f\"<p>{row['blog_summary']}</p>\")\n",
    "        \n",
    "        f.write(\"<h3>Highlights</h3>\")\n",
    "        f.write(f\"<ul><li>{'</li><li>'.join(row['highlights'].split('. '))}</li></ul>\")\n",
    "        \n",
    "        f.write(\"<h3>Issues</h3>\")\n",
    "        f.write(f\"<ul><li>{'</li><li>'.join(row['issues'].split('. '))}</li></ul>\")\n",
    "        \n",
    "        f.write('<hr>')\n",
    "    \n",
    "    f.write('</body></html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./summarizer-BART_Prefinal_v2/tokenizer_config.json',\n",
       " './summarizer-BART_Prefinal_v2/special_tokens_map.json',\n",
       " './summarizer-BART_Prefinal_v2/vocab.json',\n",
       " './summarizer-BART_Prefinal_v2/merges.txt',\n",
       " './summarizer-BART_Prefinal_v2/added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./summarizer-BART_Prefinal_v2\")\n",
    "tokenizer.save_pretrained(\"./summarizer-BART_Prefinal_v2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
