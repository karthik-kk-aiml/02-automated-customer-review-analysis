{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RoBERTa Model for Sentiment Analysis and classification with the Rating converted into labels (postive, neutral, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Hugging Face Transformers and datasets\n",
    "#!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 11:16:59.525450: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-14 11:16:59.525504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-14 11:16:59.526676: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-14 11:16:59.533434: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-14 11:17:00.272006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import nltk.classify.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.classify import NaiveBayesClassifier      # NaiveBayes classifer for comparison with RoBERTa transformer model\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_208/1209413327.py:1: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"dataset/1429_1.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.dateAdded</th>\n",
       "      <th>reviews.dateSeen</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>very fast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>Beginner tablet for our 9 year old son.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DaveZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>Good!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-12T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>Fantastic Tablet for kids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>explore42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               name  \\\n",
       "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "\n",
       "        asins   brand                                         categories  \\\n",
       "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "3  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "4  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "\n",
       "                                                keys manufacturer  \\\n",
       "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "\n",
       "               reviews.date     reviews.dateAdded  \\\n",
       "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "3  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "4  2017-01-12T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "\n",
       "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
       "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "3  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "4  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "\n",
       "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
       "0        NaN                 0.0             5.0   \n",
       "1        NaN                 0.0             5.0   \n",
       "2        NaN                 0.0             5.0   \n",
       "3        NaN                 0.0             4.0   \n",
       "4        NaN                 0.0             5.0   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "3  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "4  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  This product so far has not disappointed. My c...   \n",
       "1  great for beginner or experienced person. Boug...   \n",
       "2  Inexpensive tablet for him to use and learn on...   \n",
       "3  I've had my Fire HD 8 two weeks now and I love...   \n",
       "4  I bought this for my grand daughter when she c...   \n",
       "\n",
       "                             reviews.title reviews.userCity  \\\n",
       "0                                   Kindle              NaN   \n",
       "1                                very fast              NaN   \n",
       "2  Beginner tablet for our 9 year old son.              NaN   \n",
       "3                                  Good!!!              NaN   \n",
       "4                Fantastic Tablet for kids              NaN   \n",
       "\n",
       "   reviews.userProvince  reviews.username  \n",
       "0                   NaN           Adapter  \n",
       "1                   NaN            truman  \n",
       "2                   NaN             DaveZ  \n",
       "3                   NaN            Shacks  \n",
       "4                   NaN         explore42  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"dataset/1429_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34660, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34627, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where Rating ('Reviews.rating') is missing - about 33 of them in the entire 30K dataset (less than .1%) \n",
    "df = df.dropna(subset=['reviews.rating'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        reviews.text  reviews.rating  label\n",
      "0  This product so far has not disappointed. My c...             5.0      2\n",
      "1  great for beginner or experienced person. Boug...             5.0      2\n",
      "2  Inexpensive tablet for him to use and learn on...             5.0      2\n",
      "3  I've had my Fire HD 8 two weeks now and I love...             4.0      2\n",
      "4  I bought this for my grand daughter when she c...             5.0      2\n",
      "(34626, 22)\n"
     ]
    }
   ],
   "source": [
    "# Add a 'label' column based on 'reviews.rating' which will indicate if it's positive or negative\n",
    "def label_sentiment(rating):\n",
    "    if rating in [1, 2]:\n",
    "        return 0  # Negative\n",
    "    elif rating == 3:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 2  # Positive\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['label'] = df['reviews.rating'].apply(label_sentiment)\n",
    "\n",
    "# Drop rows where 'reviews.text' is missing (if any)\n",
    "df = df.dropna(subset=['reviews.text'])\n",
    "\n",
    "# Check the new DataFrame structure\n",
    "print(df[['reviews.text', 'reviews.rating', 'label']].head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 27700\n",
      "Validation set size: 6926\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into Train and Validation set\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['reviews.text'].tolist(), \n",
    "                                                                    df['label'].tolist(), \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train_texts)}\")\n",
    "print(f\"Validation set size: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize the text data\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings   = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets from the tokenized ones above, so it can be used in the Model\n",
    "\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained RoBERTa model for classification, this needs to be trained with our Data\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)  # 3 labels (negative, neutral, positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Defining how the model will be trained - setting training arguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=16,  # Batch size for training\n",
    "    per_device_eval_batch_size=64,   # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    evaluation_strategy=\"steps\",     # Evaluate every X steps\n",
    "    logging_steps=500,               # Log every X steps\n",
    "    save_steps=1000,                 # Save model every X steps\n",
    "    save_total_limit=2,              # Save only the 2 most recent models\n",
    "    load_best_model_at_end=True,     # Load the best model after training\n",
    "    eval_steps=500                   # Evaluation frequency\n",
    ")\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer - with all the defined info from above.\n",
    "trainer = Trainer(\n",
    "    model=model,                         # pre-trained RoBERTa model\n",
    "    args=training_args,                  # Training arguments as defined above\n",
    "    train_dataset=train_dataset,         # Training dataset\n",
    "    eval_dataset=val_dataset,            # Validation dataset\n",
    "    tokenizer=tokenizer,                 # Tokenizer\n",
    "    data_collator=data_collator          # Data collator for padding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5196' max='5196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5196/5196 10:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>0.217232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.201940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.179519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.201721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.213625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.190740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.192643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.199184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.214675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.211327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5196, training_loss=0.1890935971243185, metrics={'train_runtime': 628.0702, 'train_samples_per_second': 132.31, 'train_steps_per_second': 8.273, 'total_flos': 5466181253299200.0, 'train_loss': 0.1890935971243185, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model now to fine-tune the model for our customer review purposes\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment-analysis-roberta/tokenizer_config.json',\n",
       " './sentiment-analysis-roberta/special_tokens_map.json',\n",
       " './sentiment-analysis-roberta/vocab.json',\n",
       " './sentiment-analysis-roberta/merges.txt',\n",
       " './sentiment-analysis-roberta/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./sentiment-analysis-roberta\")\n",
    "tokenizer.save_pretrained(\"./sentiment-analysis-roberta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19074030220508575, 'eval_runtime': 10.8041, 'eval_samples_per_second': 641.05, 'eval_steps_per_second': 10.089, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using validation data\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "# Get the predictions and labels from the evaluation set\n",
    "predictions = trainer.predict(val_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = predictions.label_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the original texts used for validation in `val_texts`\n",
    "texts = val_texts  # This should be a list of the review texts used for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9467224949465781\n",
      "Precision: 0.9344681548270097\n",
      "Recall: 0.9467224949465781\n",
      "F1-Score: 0.9380985771685646\n",
      "Confusion Matrix:\n",
      "[[  64   29   64]\n",
      " [  14   65  199]\n",
      " [  12   51 6428]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "            xticklabels=[\"Negative\", \"Neutral\", \"Positive\"], \n",
    "            yticklabels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Confusion Matrix\", fontsize=16)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "plt.ylabel(\"True Label\", fontsize=14)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import matplotlib.pyplot as plt\\nimport numpy as np\\nfrom sklearn.metrics import roc_curve, auc\\n\\n# Assuming predictions and labels are obtained from trainer.predict(val_dataset)\\npredictions = trainer.predict(val_dataset)\\npreds_prob = predictions.predictions  # Get probabilities (logits)\\nlabels = predictions.label_ids  # True labels\\n\\n# If your labels are multi-class, you need to binarize them for ROC\\n# For binary classification (e.g., Positive vs Negative), use the positive class probabilities\\n# In this case, let's assume class 2 is positive (adjust based on your classes)\\npreds_positive_prob = preds_prob[:, 2]  # Extract positive class probabilities\\n\\n# Get false positive rate (FPR), true positive rate (TPR), and thresholds\\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels, preds_positive_prob, pos_label=2)\\n\\n# Calculate AUC\\nroc_auc = auc(false_positive_rate, true_positive_rate)\\n\\n# Plot the ROC curve\\nplt.figure(figsize=(8, 6))\\nplt.plot(false_positive_rate, true_positive_rate, color='b', lw=2, label='RoBERTa: AUC = %0.2f' % roc_auc)\\n\\n# Plot diagonal reference line (random classifier)\\nplt.plot([0, 1], [0, 1], color='r', linestyle='--')\\n\\n# Set plot limits and labels\\nplt.xlim([0.0, 1.0])\\nplt.ylim([0.0, 1.05])\\nplt.xlabel('False Positive Rate')\\nplt.ylabel('True Positive Rate')\\nplt.title('ROC Curve for RoBERTa Model')\\nplt.legend(loc='lower right')\\n\\n# Show the plot\\nplt.show() \""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Assuming predictions and labels are obtained from trainer.predict(val_dataset)\n",
    "predictions = trainer.predict(val_dataset)\n",
    "preds_prob = predictions.predictions  # Get probabilities (logits)\n",
    "labels = predictions.label_ids  # True labels\n",
    "\n",
    "# If your labels are multi-class, you need to binarize them for ROC\n",
    "# For binary classification (e.g., Positive vs Negative), use the positive class probabilities\n",
    "# In this case, let's assume class 2 is positive (adjust based on your classes)\n",
    "preds_positive_prob = preds_prob[:, 2]  # Extract positive class probabilities\n",
    "\n",
    "# Get false positive rate (FPR), true positive rate (TPR), and thresholds\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(labels, preds_positive_prob, pos_label=2)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='b', lw=2, label='RoBERTa: AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Plot diagonal reference line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n",
    "\n",
    "# Set plot limits and labels\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for RoBERTa Model')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'val_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'text' from the val_dataset which is a Tensorfile now.\n",
    "texts = val_texts  # This should be a list of the review texts used for validation\n",
    "\n",
    "# Create a DataFrame with the texts, true labels, and predicted labels\n",
    "df_results = pd.DataFrame({\n",
    "    'Text': texts,\n",
    "    'True Label': labels,\n",
    "    'Predicted Label': preds\n",
    "})\n",
    "\n",
    "# Save the DataFrame as a CSV file for further analysis\n",
    "df_results.to_csv(\"val_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to 'val_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(new_review, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get model predictions\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m label_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeutral\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py:828\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    836\u001b[0m     embedding_output,\n\u001b[1;32m    837\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    845\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py:125\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    122\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    128\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# Example: Inference with new review\n",
    "new_review = \"This product is amazing, I love it!\"\n",
    "inputs = tokenizer(new_review, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Get model predictions\n",
    "outputs = model(**inputs)\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "label_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "print(f\"Sentiment: {label_mapping[predictions.item()]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
