{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizer with T5-Base model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install transformers huggingface_hub\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5002280262c84ec78e278c9ef2988abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba4d45e820c45e6b461c60c62e1ace9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c043b17e4f495083592b38a143a68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f31d0553cb4354a7f56971688ea60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deedc01b2dad42c6b3f3c3b50b46011c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load the T5-3B model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        category_name                                       reviews.text\n",
      "0           Fire HD 8  this product so far has not disappointed. my c...\n",
      "1           Fire KIDS  the tablet is very light and streams well. i o...\n",
      "2       Fire Tablet 7  good basic tablet for checking email , web bro...\n",
      "3              Kindle  very lightweight and portable with excellent b...\n",
      "4  Speakers/Streaming  i really enjoy the echo. i got an echo dot and...\n"
     ]
    }
   ],
   "source": [
    "# LOAD the DATA (the output DS from K-means clustering)\n",
    "file_path = \"categorized_dataset_k5_with_names.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Data cleaning: Convert reviews.text to lowercase and remove NULLs\n",
    "df[\"reviews.text\"] = df[\"reviews.text\"].astype(str).str.lower()\n",
    "df = df[df[\"reviews.text\"].notnull()]\n",
    "\n",
    "# Group all reviews under each Category\n",
    "grouped_reviews = (\n",
    "    df.groupby(\"category_name\")[\"reviews.text\"]\n",
    "    .apply(lambda texts: \" \".join(texts))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(grouped_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the CUDA cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM T5 BASE\n",
    "\n",
    "# List of common pronouns to remove\n",
    "pronouns = [\n",
    "    \"i\",\n",
    "    \"you\",\n",
    "    \"he\",\n",
    "    \"she\",\n",
    "    \"we\",\n",
    "    \"they\",\n",
    "    \"my\",\n",
    "    \"your\",\n",
    "    \"his\",\n",
    "    \"her\",\n",
    "    \"our\",\n",
    "    \"their\",\n",
    "    \"us\",\n",
    "    \"me\",\n",
    "    \"ll\",\n",
    "    \"have\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to remove pronouns\n",
    "def remove_pronouns(text):\n",
    "    text = re.sub(r\"\\b(?:{})\\b\".format(\"|\".join(pronouns)), \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Summarization function for blog-style summaries\n",
    "def generate_blog_style_summary(text):\n",
    "    cleaned_text = remove_pronouns(text)\n",
    "    input_text = (\n",
    "        \"summarize: write a blog-style summary about the product features and exclude any personal mentions. \"\n",
    "        + cleaned_text\n",
    "    )\n",
    "    inputs = tokenizer.encode(\n",
    "        input_text, return_tensors=\"pt\", max_length=512, truncation=True\n",
    "    )\n",
    "\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=300,\n",
    "        min_length=150,\n",
    "        num_beams=6,\n",
    "        length_penalty=2.5,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Generate both blog-style summary\n",
    "grouped_reviews[\"blog_style_summary\"] = grouped_reviews[\"reviews.text\"].apply(\n",
    "    generate_blog_style_summary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        category_name                                       reviews.text  \\\n",
      "0           Fire HD 8  this product so far has not disappointed. my c...   \n",
      "1           Fire KIDS  the tablet is very light and streams well. i o...   \n",
      "2       Fire Tablet 7  good basic tablet for checking email , web bro...   \n",
      "3              Kindle  very lightweight and portable with excellent b...   \n",
      "4  Speakers/Streaming  i really enjoy the echo. i got an echo dot and...   \n",
      "\n",
      "                                  blog_style_summary  \n",
      "0  amazon fire 8 inch tablet is great for e-readi...  \n",
      "1  this is the second amazon fire 7 tablet purcha...  \n",
      "2  great basic tablet for checking email, web bro...  \n",
      "3  the kindle oasis is very tiny, portable & fits...  \n",
      "4  the echo dot has the same capability as the fu...  \n"
     ]
    }
   ],
   "source": [
    "print(grouped_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final summaries to a CSV file\n",
    "# grouped_reviews.to_csv(\"T5-base_summary_prefinal.csv\", index=False)\n",
    "\n",
    "# Write the summaries to an HTML file\n",
    "with open(\"T5-base_summary_prefinal_1.html\", \"w\") as f:\n",
    "    for index, row in grouped_reviews.iterrows():\n",
    "        f.write(f\"<h2>Product: {row['category_name']}</h2>\\n\")\n",
    "        f.write(f\"<p>{row['blog_style_summary']}</p>\\n\")\n",
    "        f.write(\"<hr>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./summarizer-T5_Base_Prefinal/tokenizer_config.json',\n",
       " './summarizer-T5_Base_Prefinal/special_tokens_map.json',\n",
       " './summarizer-T5_Base_Prefinal/spiece.model',\n",
       " './summarizer-T5_Base_Prefinal/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./summarizer-T5_Base_Prefinal\")\n",
    "tokenizer.save_pretrained(\"./summarizer-T5_Base_Prefinal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# Load T5-Base model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of common pronouns to remove\n",
    "pronouns = [\n",
    "    \"i\",\n",
    "    \"you\",\n",
    "    \"he\",\n",
    "    \"she\",\n",
    "    \"we\",\n",
    "    \"they\",\n",
    "    \"my\",\n",
    "    \"your\",\n",
    "    \"his\",\n",
    "    \"her\",\n",
    "    \"our\",\n",
    "    \"their\",\n",
    "    \"us\",\n",
    "    \"me\",\n",
    "    \"ll\",\n",
    "    \"have\",\n",
    "]\n",
    "\n",
    "\n",
    "def remove_pronouns(text, pronouns):\n",
    "    # Remove pronouns using a regular expression\n",
    "    pattern = r\"\\b(?:\" + \"|\".join(pronouns) + r\")\\b\"\n",
    "    return re.sub(pattern, \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "def generate_summary(text, prompt=\"summarize:\"):\n",
    "    # Clean the text by removing pronouns\n",
    "    text = remove_pronouns(text, pronouns)\n",
    "\n",
    "    # Create input prompt for T5\n",
    "    input_text = f\"{prompt} {text}\"\n",
    "    inputs = tokenizer.encode(\n",
    "        input_text, return_tensors=\"pt\", max_length=1024, truncation=True\n",
    "    )\n",
    "    summary_ids = model.generate(\n",
    "        inputs, max_length=150, num_beams=4, length_penalty=1.5, early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Function to generate general and issue summaries per category\n",
    "def generate_summaries(df):\n",
    "    results = []\n",
    "\n",
    "    for category in df[\"category_name\"].unique():\n",
    "        category_df = df[df[\"category_name\"] == category]\n",
    "\n",
    "        # General summary (label = 2)\n",
    "        # general_reviews = ' '.join(category_df['reviews.text'].tolist())\n",
    "        general_reviews = \" \".join(\n",
    "            category_df[category_df[\"label\"] == 2][\"reviews.text\"].tolist()\n",
    "        )\n",
    "        general_summary = generate_summary(general_reviews)\n",
    "\n",
    "        # Issue summary (label = 0)\n",
    "        issue_reviews = \" \".join(\n",
    "            category_df[category_df[\"label\"] == 0][\"reviews.text\"].tolist()\n",
    "        )\n",
    "        issue_summary = generate_summary(issue_reviews, prompt=\"summarize the issues:\")\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"category_name\": category,\n",
    "                \"general_summary\": general_summary,\n",
    "                \"issues_summary\": issue_summary,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Load data for processing\n",
    "df = pd.read_csv(file_path)\n",
    "summaries_df = generate_summaries(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to HTML\n",
    "with open(\"T5-base_summary_prefinal_2.html\", \"w\") as f:\n",
    "    for _, row in summaries_df.iterrows():\n",
    "        f.write(f\"<h2>Product: {row['category_name']}</h2>\\n\")\n",
    "        f.write(f\"<h3>Highlights:</h3>\\n<p>{row['general_summary']}</p>\\n\")\n",
    "        f.write(f\"<h3>Issues:</h3>\\n<p>{row['issues_summary']}</p>\\n\")\n",
    "        f.write(\"<hr>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final HTML output created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/1233476729.py:19: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  highlights = h2.find_next(\"h3\", text=\"Highlights:\").find_next(\"p\").get_text()\n",
      "/tmp/ipykernel_40/1233476729.py:20: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  issues = h2.find_next(\"h3\", text=\"Issues:\").find_next(\"p\").get_text()\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Function to load HTML content and parse it\n",
    "def load_html_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "    return BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "\n",
    "# Load the two HTML files\n",
    "general_soup = load_html_file(\"T5-base_summary_prefinal_1.html\")  # General summaries\n",
    "issues_soup = load_html_file(\"T5-base_summary_prefinal_2.html\")  # Highlights and issues\n",
    "\n",
    "# Create a dictionary from the highlights and issues file\n",
    "issues_dict = {}\n",
    "for h2 in issues_soup.find_all(\"h2\"):\n",
    "    category = h2.get_text()\n",
    "    highlights = h2.find_next(\"h3\", text=\"Highlights:\").find_next(\"p\").get_text()\n",
    "    issues = h2.find_next(\"h3\", text=\"Issues:\").find_next(\"p\").get_text()\n",
    "    issues_dict[category] = {\"highlights\": highlights, \"issues\": issues}\n",
    "\n",
    "# Combine the content by matching category_name\n",
    "final_html = \"<html><body>\\n\"\n",
    "for h2 in general_soup.find_all(\"h2\"):\n",
    "    category = h2.get_text()\n",
    "    summary = h2.find_next(\"p\").get_text()\n",
    "\n",
    "    final_html += f\"<h2>{category}</h2>\\n\"\n",
    "    final_html += f\"<h3>General Summary:</h3>\\n<p>{summary}</p>\\n\"\n",
    "\n",
    "    # Add highlights and issues if available\n",
    "    if category in issues_dict:\n",
    "        final_html += (\n",
    "            f\"<h3>Highlights:</h3>\\n<p>{issues_dict[category]['highlights']}</p>\\n\"\n",
    "        )\n",
    "        final_html += f\"<h3>Issues:</h3>\\n<p>{issues_dict[category]['issues']}</p>\\n\"\n",
    "\n",
    "    final_html += \"<hr>\\n\"\n",
    "\n",
    "final_html += \"</body></html>\"\n",
    "\n",
    "# Save the combined result to a new HTML file\n",
    "with open(\n",
    "    \"T5_Base_Final_Product_Summary.html\", \"w\", encoding=\"utf-8\"\n",
    ") as f:  # Consolidated output HTML file\n",
    "    f.write(final_html)\n",
    "\n",
    "print(\"Final HTML output created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://583035d64525dd8799.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://583035d64525dd8799.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Function to load and parse the HTML file\n",
    "def load_html_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    products = []\n",
    "    for product in soup.find_all(\"h2\"):\n",
    "        product_name = product.get_text().replace(\"Product: \", \"\").strip()\n",
    "        general_summary = product.find_next(\"p\").get_text().strip()\n",
    "        highlights = product.find_next(\"p\").find_next(\"p\").get_text().strip()\n",
    "        issues = product.find_next(\"p\").find_next(\"p\").find_next(\"p\").get_text().strip()\n",
    "\n",
    "        products.append(\n",
    "            {\n",
    "                \"product\": product_name,\n",
    "                \"general_summary\": general_summary,\n",
    "                \"highlights\": highlights,\n",
    "                \"issues\": issues,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return products\n",
    "\n",
    "\n",
    "# Load the HTML content\n",
    "html_file_path = \"T5_Base_Final_Product_Summary.html\"  # Consolidated File\n",
    "products_data = load_html_file(html_file_path)\n",
    "\n",
    "\n",
    "# Gradio function to return the summary based on the selected product\n",
    "def show_product_details(product_name):\n",
    "    for product in products_data:\n",
    "        if product[\"product\"] == product_name:\n",
    "            return (\n",
    "                product[\"general_summary\"],\n",
    "                product[\"highlights\"],\n",
    "                product[\"issues\"],\n",
    "            )\n",
    "    return \"Not available\", \"Not available\", \"Not available\"\n",
    "\n",
    "\n",
    "# Gradio interface setup\n",
    "product_list = [\n",
    "    product[\"product\"] for product in products_data\n",
    "]  # List of product names\n",
    "\n",
    "gr.Interface(\n",
    "    fn=show_product_details,\n",
    "    inputs=gr.Dropdown(choices=product_list, label=\"Select Product\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"General Summary\"),\n",
    "        gr.Textbox(label=\"Highlights\"),\n",
    "        gr.Textbox(label=\"Issues\"),\n",
    "    ],\n",
    "    title=\"Product Review Summaries\",\n",
    "    description=\"Select a product to view the general summary, highlights, and issues.\",\n",
    ").launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
