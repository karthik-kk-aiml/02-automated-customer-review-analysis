{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install transformers huggingface_hub\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the T5-3B model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        category_name                                       reviews.text\n",
      "0           Fire HD 8  this product so far has not disappointed. my c...\n",
      "1           Fire KIDS  the tablet is very light and streams well. i o...\n",
      "2       Fire Tablet 7  good basic tablet for checking email , web bro...\n",
      "3              Kindle  very lightweight and portable with excellent b...\n",
      "4  Speakers/Streaming  i really enjoy the echo. i got an echo dot and...\n"
     ]
    }
   ],
   "source": [
    "# LOAD the DATA (the output DS from K-means clustering)\n",
    "file_path = 'categorized_dataset_k5_with_names.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Data cleaning: Convert reviews.text to lowercase and remove NULLs\n",
    "df['reviews.text'] = df['reviews.text'].astype(str).str.lower()\n",
    "df = df[df['reviews.text'].notnull()]\n",
    "\n",
    "# Group all reviews under each Category \n",
    "grouped_reviews = df.groupby('category_name')['reviews.text'].apply(lambda texts: ' '.join(texts)).reset_index() \n",
    "\n",
    "print(grouped_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the CUDA cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM T5 BASE - 11:30AM\n",
    "\n",
    "# List of common pronouns to remove\n",
    "pronouns = ['i', 'you', 'he', 'she', 'we', 'they', 'my', 'your', 'his', 'her', 'our', 'their', 'us', 'me', 'll', 'have']\n",
    "\n",
    "# Function to remove pronouns\n",
    "def remove_pronouns(text):\n",
    "    text = re.sub(r'\\b(?:{})\\b'.format('|'.join(pronouns)), '', text)\n",
    "    return text\n",
    "\n",
    "# Summarization function for blog-style summaries\n",
    "def generate_blog_style_summary(text):\n",
    "    cleaned_text = remove_pronouns(text)\n",
    "    input_text = \"summarize: write a blog-style summary about the product features and exclude any personal mentions. \" + cleaned_text\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    summary_ids = model.generate(inputs, max_length=300, min_length=150, num_beams=6, length_penalty=2.5, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Generate both blog-style summary\n",
    "grouped_reviews['blog_style_summary'] = grouped_reviews['reviews.text'].apply(generate_blog_style_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        category_name                                       reviews.text  \\\n",
      "0           Fire HD 8  this product so far has not disappointed. my c...   \n",
      "1           Fire KIDS  the tablet is very light and streams well. i o...   \n",
      "2       Fire Tablet 7  good basic tablet for checking email , web bro...   \n",
      "3              Kindle  very lightweight and portable with excellent b...   \n",
      "4  Speakers/Streaming  i really enjoy the echo. i got an echo dot and...   \n",
      "\n",
      "                                  blog_style_summary  \n",
      "0  amazon fire 8 is a great tablet for e-reading ...  \n",
      "1  this is the second amazon fire 7 tablet purcha...  \n",
      "2  this is a great tablet for kids 6 and older. i...  \n",
      "3  the kindle oasis is the smallest of all the ki...  \n",
      "4  the echo dot has the same capability as the fu...  \n"
     ]
    }
   ],
   "source": [
    "print(grouped_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final summaries to a CSV file\n",
    "grouped_reviews.to_csv(\"T5-base_summary_prefinal.csv\", index=False)\n",
    "\n",
    "# Write the summaries to an HTML file\n",
    "with open(\"T5-base_summary_prefinal.html\", \"w\") as f:\n",
    "    for index, row in grouped_reviews.iterrows():\n",
    "        f.write(f\"<h2>Product: {row['category_name']}</h2>\\n\")\n",
    "        f.write(f\"<p>{row['blog_style_summary']}</p>\\n\")\n",
    "        f.write(\"<hr>\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./summarizer-T5_Base_v0/tokenizer_config.json',\n",
       " './summarizer-T5_Base_v0/special_tokens_map.json',\n",
       " './summarizer-T5_Base_v0/spiece.model',\n",
       " './summarizer-T5_Base_v0/added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./summarizer-T5_Base_Prefinal\")\n",
    "tokenizer.save_pretrained(\"./summarizer-T5_Base_Prefinal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio\n",
    "#!pip install gradio beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://59f658175f598076ec.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://59f658175f598076ec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to load and parse the HTML file\n",
    "def load_html_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    categories = [h2.get_text() for h2 in soup.find_all('h2')]\n",
    "    summaries = [p.get_text() for p in soup.find_all('p')]\n",
    "    return dict(zip(categories, summaries))\n",
    "\n",
    "# Load the HTML content\n",
    "html_file_path = \"T5-base_summaries_Prefinal.html\"  # Path to your HTML file\n",
    "data = load_html_file(html_file_path)\n",
    "\n",
    "# Gradio function to return the summary based on the selected category\n",
    "def show_summary(category):\n",
    "    return data.get(category, \"Summary not available.\")\n",
    "\n",
    "# Gradio interface\n",
    "category_list = list(data.keys())  # List of categories\n",
    "\n",
    "gr.Interface(\n",
    "    fn=show_summary,\n",
    "    inputs=gr.Dropdown(choices=category_list, label=\"Select Product\"),  # Updated for Gradio 3.x+\n",
    "    outputs=gr.Textbox(),  # Updated for Gradio 3.x+\n",
    "    title=\"Product Review\",\n",
    "    description=\"Select a product to see the review.\"\n",
    ").launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
