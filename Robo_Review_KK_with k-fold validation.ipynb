{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RoBERTa Model for Sentiment Analysis and classification with the Rating converted into labels (postive, neutral, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 17:04:15.856531: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-14 17:04:15.856630: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-14 17:04:15.857753: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-14 17:04:15.864296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-14 17:04:16.631568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import nltk.classify.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.classify import NaiveBayesClassifier      # NaiveBayes classifer for comparison with RoBERTa transformer model\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Hugging Face Transformers and datasets\n",
    "#!pip install transformers datasets # not needed to be installed any more!!!\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40/1209413327.py:1: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"dataset/1429_1.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.dateAdded</th>\n",
       "      <th>reviews.dateSeen</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>very fast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>Beginner tablet for our 9 year old son.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DaveZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>Good!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-12T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>Fantastic Tablet for kids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>explore42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               name  \\\n",
       "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "\n",
       "        asins   brand                                         categories  \\\n",
       "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "3  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "4  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "\n",
       "                                                keys manufacturer  \\\n",
       "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "\n",
       "               reviews.date     reviews.dateAdded  \\\n",
       "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "3  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "4  2017-01-12T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "\n",
       "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
       "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "3  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "4  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "\n",
       "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
       "0        NaN                 0.0             5.0   \n",
       "1        NaN                 0.0             5.0   \n",
       "2        NaN                 0.0             5.0   \n",
       "3        NaN                 0.0             4.0   \n",
       "4        NaN                 0.0             5.0   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "3  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "4  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  This product so far has not disappointed. My c...   \n",
       "1  great for beginner or experienced person. Boug...   \n",
       "2  Inexpensive tablet for him to use and learn on...   \n",
       "3  I've had my Fire HD 8 two weeks now and I love...   \n",
       "4  I bought this for my grand daughter when she c...   \n",
       "\n",
       "                             reviews.title reviews.userCity  \\\n",
       "0                                   Kindle              NaN   \n",
       "1                                very fast              NaN   \n",
       "2  Beginner tablet for our 9 year old son.              NaN   \n",
       "3                                  Good!!!              NaN   \n",
       "4                Fantastic Tablet for kids              NaN   \n",
       "\n",
       "   reviews.userProvince  reviews.username  \n",
       "0                   NaN           Adapter  \n",
       "1                   NaN            truman  \n",
       "2                   NaN             DaveZ  \n",
       "3                   NaN            Shacks  \n",
       "4                   NaN         explore42  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"dataset/1429_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34660, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34627, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where Rating ('Reviews.rating') is missing - about 33 of them in the entire 30K dataset (less than .1%) \n",
    "df = df.dropna(subset=['reviews.rating'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        reviews.text  reviews.rating  label\n",
      "0  This product so far has not disappointed. My c...             5.0      2\n",
      "1  great for beginner or experienced person. Boug...             5.0      2\n",
      "2  Inexpensive tablet for him to use and learn on...             5.0      2\n",
      "3  I've had my Fire HD 8 two weeks now and I love...             4.0      2\n",
      "4  I bought this for my grand daughter when she c...             5.0      2\n",
      "(34626, 22)\n"
     ]
    }
   ],
   "source": [
    "# Add a 'label' column based on 'reviews.rating' which will indicate if it's positive or negative\n",
    "def label_sentiment(rating):\n",
    "    if rating in [1, 2]:\n",
    "        return 0  # Negative\n",
    "    elif rating == 3:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 2  # Positive\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['label'] = df['reviews.rating'].apply(label_sentiment)\n",
    "\n",
    "# Drop rows where 'reviews.text' is missing (if any)\n",
    "df = df.dropna(subset=['reviews.text'])\n",
    "\n",
    "# Check the new DataFrame structure\n",
    "print(df[['reviews.text', 'reviews.rating', 'label']].head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 27700\n",
      "Validation set size: 6926\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into Train and Validation set\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['reviews.text'].tolist(), \n",
    "                                                                    df['label'].tolist(), \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train_texts)}\")\n",
    "print(f\"Validation set size: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc75731043214fdb9acc4c4fd98f7a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfadd8f25e97445ab202f95aa3b68ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained RoBERTa model for classification, this needs to be trained with our Data\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)  # 3 labels (negative, neutral, positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88c54c8cace412daab505cd81d843bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd33cfe986a422687a3d8bab4801964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf8af36a19b441bbd437a44ee1b90e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9bc412872749fe9c12416bfb4e2a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize the text data\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings   = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WeightedRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WeightedRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Due to the input dataset heavily skewed towards positive, need to introduce class weights into the model (to pump up the minority classes)\n",
    "# No changes to the Dataset\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Step 1: Compute class weights based on the training labels\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1, 2], y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Step 2: Modify the model to incorporate class weights in the loss function\n",
    "class WeightedRobertaForSequenceClassification(RobertaForSequenceClassification):\n",
    "    def __init__(self, config, class_weights):\n",
    "        super().__init__(config)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        # Perform the standard forward pass\n",
    "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        \n",
    "        # Compute the custom loss with class weights\n",
    "        logits = outputs.logits\n",
    "        if labels is not None:\n",
    "             # Move class weights to the same device as the model (either CPU or GPU)\n",
    "            self.class_weights = self.class_weights.to(logits.device)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)  # Incorporate class weights\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            # Return the loss within the SequenceClassifierOutput structure\n",
    "            return SequenceClassifierOutput(\n",
    "                loss=loss,\n",
    "                logits=logits,\n",
    "                hidden_states=outputs.hidden_states,\n",
    "                attentions=outputs.attentions\n",
    "            )\n",
    "        else:\n",
    "        \n",
    "            return outputs\n",
    "\n",
    "# Initialize the custom model with class weights\n",
    "\n",
    "model = WeightedRobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3, class_weights=class_weights_tensor)\n",
    "\n",
    "# Move the weights to GPU as the model is already there\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Defining Training Argeuments - how the model will be trained \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory\n",
    "    num_train_epochs=2,              # Number of training epochs changed EPOCH TO 3\n",
    "    per_device_train_batch_size=16,  # Batch size for training\n",
    "    per_device_eval_batch_size=64,   # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    evaluation_strategy=\"steps\",     # Evaluate every X steps\n",
    "    logging_steps=500,               # Log every X steps\n",
    "    save_steps=1000,                 # Save model every X steps\n",
    "    save_total_limit=2,              # Save only the 2 most recent models\n",
    "    load_best_model_at_end=True,     # Load the best model after training\n",
    "    eval_steps=500                   # Evaluation frequency\n",
    ")\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets from the tokenized ones above, so it can be used in the Model\n",
    "\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create PyTorch datasetsf\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2770' max='2770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2770/2770 05:18, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.094000</td>\n",
       "      <td>0.825803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.137900</td>\n",
       "      <td>1.227443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.071500</td>\n",
       "      <td>1.145669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.040900</td>\n",
       "      <td>1.229092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.994600</td>\n",
       "      <td>0.895419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fold 1: {'eval_loss': 1.2274426221847534, 'eval_runtime': 8.8597, 'eval_samples_per_second': 625.302, 'eval_steps_per_second': 9.82, 'epoch': 2.0}\n",
      "Training fold 2/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2770' max='2770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2770/2770 05:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.056700</td>\n",
       "      <td>1.159286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.074300</td>\n",
       "      <td>1.239301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.071900</td>\n",
       "      <td>1.240097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.077500</td>\n",
       "      <td>1.136408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.058800</td>\n",
       "      <td>1.154861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fold 2: {'eval_loss': 1.1364084482192993, 'eval_runtime': 8.8814, 'eval_samples_per_second': 623.777, 'eval_steps_per_second': 9.796, 'epoch': 2.0}\n",
      "Training fold 3/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2770' max='2770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2770/2770 05:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.047400</td>\n",
       "      <td>1.208598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.075400</td>\n",
       "      <td>1.138236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.044600</td>\n",
       "      <td>1.216893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.081600</td>\n",
       "      <td>1.153596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.994800</td>\n",
       "      <td>1.321753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fold 3: {'eval_loss': 1.1382358074188232, 'eval_runtime': 8.8447, 'eval_samples_per_second': 626.363, 'eval_steps_per_second': 9.836, 'epoch': 2.0}\n",
      "Training fold 4/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2770' max='2770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2770/2770 05:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.062600</td>\n",
       "      <td>1.163069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.070200</td>\n",
       "      <td>1.149964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.056200</td>\n",
       "      <td>1.136532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.060800</td>\n",
       "      <td>1.174255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.059700</td>\n",
       "      <td>1.172368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fold 4: {'eval_loss': 1.1499637365341187, 'eval_runtime': 8.8594, 'eval_samples_per_second': 625.325, 'eval_steps_per_second': 9.82, 'epoch': 2.0}\n",
      "Training fold 5/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2770' max='2770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2770/2770 05:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.081900</td>\n",
       "      <td>1.195538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.019400</td>\n",
       "      <td>1.206365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.064200</td>\n",
       "      <td>1.170004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.070600</td>\n",
       "      <td>1.239794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.081300</td>\n",
       "      <td>1.172782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fold 5: {'eval_loss': 1.2063648700714111, 'eval_runtime': 8.8764, 'eval_samples_per_second': 624.129, 'eval_steps_per_second': 9.801, 'epoch': 2.0}\n",
      "Average Cross-Validation Results: {'eval_loss': 1.171683096885681, 'eval_runtime': 8.864320000000001, 'eval_samples_per_second': 624.9792, 'eval_steps_per_second': 9.8146, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# CROSS-VALIDATION because the class is skewed to Positive (Ratings 4 & 5) after the Class_weights implementation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Prepare for Stratified K-Fold Cross-Validation\n",
    "n_splits = 5  # Number of folds\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert your encodings and labels to NumPy arrays for easier splitting\n",
    "all_encodings_np = {key: np.array(val) for key, val in train_dataset.encodings.items()}\n",
    "all_labels_np = np.array(train_dataset.labels)\n",
    "\n",
    "# List to store results for each fold\n",
    "fold_results = []\n",
    "\n",
    "# Start Stratified K-Fold Cross-Validation\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(all_labels_np, all_labels_np)):  # stratified split\n",
    "    print(f\"Training fold {fold+1}/{n_splits}\")\n",
    "\n",
    "    # Create the training and validation datasets for this fold\n",
    "    train_encodings_fold = {key: val[train_idx] for key, val in all_encodings_np.items()}\n",
    "    val_encodings_fold = {key: val[val_idx] for key, val in all_encodings_np.items()}\n",
    "    \n",
    "    train_labels_fold = all_labels_np[train_idx]\n",
    "    val_labels_fold = all_labels_np[val_idx]\n",
    "\n",
    "    # Create PyTorch datasets for this fold from the numpy Arrays ///****** Important step as only Pytorch can be processed by RoBERTa  model **///\n",
    "    train_dataset_fold = SentimentDataset(train_encodings_fold, train_labels_fold)\n",
    "    val_dataset_fold = SentimentDataset(val_encodings_fold, val_labels_fold)\n",
    "\n",
    "    # Initialize Trainer for this fold\n",
    "    trainer = Trainer(\n",
    "        model=model,                         # Pre-trained RoBERTa model\n",
    "        args=training_args,                  # Training arguments\n",
    "        train_dataset=train_dataset_fold,    # Training dataset for the current fold\n",
    "        eval_dataset=val_dataset_fold,       # Validation dataset for the current fold\n",
    "        tokenizer=tokenizer,                 # Tokenizer\n",
    "        data_collator=data_collator          # Data collator for padding\n",
    "    )\n",
    "\n",
    "    # Train the model on this fold\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model on the validation set for this fold\n",
    "    eval_results = trainer.evaluate()\n",
    "    \n",
    "    # Save the results for this fold\n",
    "    fold_results.append(eval_results)\n",
    "    \n",
    "    # Print results for this fold\n",
    "    print(f\"Results for fold {fold+1}: {eval_results}\")\n",
    "\n",
    "# After all folds, aggregate and print the results\n",
    "avg_results = {\n",
    "    metric: np.mean([fold[metric] for fold in fold_results])\n",
    "    for metric in fold_results[0].keys()\n",
    "}\n",
    "\n",
    "print(f\"Average Cross-Validation Results: {avg_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Initialize the Trainer - with all the defined info from above.\\ntrainer = Trainer(\\n    model=model,                         # pre-trained RoBERTa model\\n    args=training_args,                  # Training arguments as defined above\\n    train_dataset=train_dataset,         # Training dataset\\n    eval_dataset=val_dataset,            # Validation dataset\\n    tokenizer=tokenizer,                 # Tokenizer\\n    data_collator=data_collator          # Data collator for padding\\n) '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Initialize the Trainer - with all the defined info from above.\n",
    "trainer = Trainer(\n",
    "    model=model,                         # pre-trained RoBERTa model\n",
    "    args=training_args,                  # Training arguments as defined above\n",
    "    train_dataset=train_dataset,         # Training dataset\n",
    "    eval_dataset=val_dataset,            # Validation dataset\n",
    "    tokenizer=tokenizer,                 # Tokenizer\n",
    "    data_collator=data_collator          # Data collator for padding\n",
    ") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Train the model now to fine-tune the model for our customer review purposes\\ntrainer.train() '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Train the model now to fine-tune the model for our customer review purposes\n",
    "trainer.train() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment-analysis-roberta-CrossV-Classweight2/tokenizer_config.json',\n",
       " './sentiment-analysis-roberta-CrossV-Classweight2/special_tokens_map.json',\n",
       " './sentiment-analysis-roberta-CrossV-Classweight2/vocab.json',\n",
       " './sentiment-analysis-roberta-CrossV-Classweight2/merges.txt',\n",
       " './sentiment-analysis-roberta-CrossV-Classweight2/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./sentiment-analysis-roberta-CrossV-Classweight2\")\n",
    "tokenizer.save_pretrained(\"./sentiment-analysis-roberta-CrossV-Classweight2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from transformers import RobertaForSequenceClassification, RobertaTokenizer\\n\\n# Reload model and tokenizer\\nmodel = RobertaForSequenceClassification.from_pretrained(\"./sentiment-analysis-roberta\")\\ntokenizer = RobertaTokenizer.from_pretrained(\"./sentiment-analysis-roberta\") '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "# Reload model and tokenizer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"./sentiment-analysis-roberta\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"./sentiment-analysis-roberta\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2063648700714111, 'eval_runtime': 8.8728, 'eval_samples_per_second': 624.383, 'eval_steps_per_second': 9.805, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using validation data\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "# Get the predictions and labels from the evaluation set\n",
    "predictions = trainer.predict(val_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = predictions.label_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9371931850996246\n",
      "Precision: 0.8783310661971793\n",
      "Recall: 0.9371931850996246\n",
      "F1-Score: 0.9068079249432307\n",
      "Confusion Matrix:\n",
      "[[   0    0  157]\n",
      " [   0    0  278]\n",
      " [   0    0 6491]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"viridis\", cbar=False, \n",
    "            xticklabels=[\"Negative\", \"Neutral\", \"Positive\"], \n",
    "            yticklabels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Confusion Matrix\", fontsize=16)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "plt.ylabel(\"True Label\", fontsize=14)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import matplotlib.pyplot as plt\\nimport numpy as np\\nfrom sklearn.metrics import roc_curve, auc\\n\\n# Assuming predictions and labels are obtained from trainer.predict(val_dataset)\\npredictions = trainer.predict(val_dataset)\\npreds_prob = predictions.predictions  # Get probabilities (logits)\\nlabels = predictions.label_ids  # True labels\\n\\n# If your labels are multi-class, you need to binarize them for ROC\\n# For binary classification (e.g., Positive vs Negative), use the positive class probabilities\\n# In this case, let's assume class 2 is positive (adjust based on your classes)\\npreds_positive_prob = preds_prob[:, 2]  # Extract positive class probabilities\\n\\n# Get false positive rate (FPR), true positive rate (TPR), and thresholds\\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels, preds_positive_prob, pos_label=2)\\n\\n# Calculate AUC\\nroc_auc = auc(false_positive_rate, true_positive_rate)\\n\\n# Plot the ROC curve\\nplt.figure(figsize=(8, 6))\\nplt.plot(false_positive_rate, true_positive_rate, color='b', lw=2, label='RoBERTa: AUC = %0.2f' % roc_auc)\\n\\n# Plot diagonal reference line (random classifier)\\nplt.plot([0, 1], [0, 1], color='r', linestyle='--')\\n\\n# Set plot limits and labels\\nplt.xlim([0.0, 1.0])\\nplt.ylim([0.0, 1.05])\\nplt.xlabel('False Positive Rate')\\nplt.ylabel('True Positive Rate')\\nplt.title('ROC Curve for RoBERTa Model')\\nplt.legend(loc='lower right')\\n\\n# Show the plot\\nplt.show() \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Assuming predictions and labels are obtained from trainer.predict(val_dataset)\n",
    "predictions = trainer.predict(val_dataset)\n",
    "preds_prob = predictions.predictions  # Get probabilities (logits)\n",
    "labels = predictions.label_ids  # True labels\n",
    "\n",
    "# If your labels are multi-class, you need to binarize them for ROC\n",
    "# For binary classification (e.g., Positive vs Negative), use the positive class probabilities\n",
    "# In this case, let's assume class 2 is positive (adjust based on your classes)\n",
    "preds_positive_prob = preds_prob[:, 2]  # Extract positive class probabilities\n",
    "\n",
    "# Get false positive rate (FPR), true positive rate (TPR), and thresholds\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(labels, preds_positive_prob, pos_label=2)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='b', lw=2, label='RoBERTa: AUC = %0.2f' % roc_auc)\n",
    "\n",
    "# Plot diagonal reference line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], color='r', linestyle='--')\n",
    "\n",
    "# Set plot limits and labels\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for RoBERTa Model')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'val_predictions2.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'text' from the val_dataset which is a Tensorfile now.\n",
    "texts = val_texts  # This should be a list of the review texts used for validation\n",
    "\n",
    "# Create a DataFrame with the texts, true labels, and predicted labels\n",
    "df_results = pd.DataFrame({\n",
    "    'Text': texts,\n",
    "    'True Label': labels,\n",
    "    'Predicted Label': preds\n",
    "})\n",
    "\n",
    "# Save the DataFrame as a CSV file for further analysis\n",
    "df_results.to_csv(\"val_predictions1.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to 'val_predictions2.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(new_review, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Get model predictions\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m label_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeutral\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m, in \u001b[0;36mWeightedRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, labels, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Perform the standard forward pass\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Compute the custom loss with class weights\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py:828\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    836\u001b[0m     embedding_output,\n\u001b[1;32m    837\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    845\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py:125\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    122\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    128\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# DEFINE THE CUDA statement so it can pick up from GPU or speaker\n",
    "\n",
    "# Example: Inference with new review\n",
    "new_review = \"This product is amazing, I love it!\"\n",
    "inputs = tokenizer(new_review, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Get model predictions\n",
    "outputs = model(**inputs)\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "label_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "print(f\"Sentiment: {label_mapping[predictions.item()]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
